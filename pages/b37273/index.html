<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>01-VIP-Kafka快速实战与基本原理详解(2) | 学习笔记</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="web前端技术博客,专注web前端学习与总结。JavaScript,js,ES6,TypeScript,vue,React,python,css3,html5,Node,git,github等技术文章。">
    <meta name="keywords" content="个人技术博客,技术文档,学习,面试,markdown">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.b0792086.css" as="style"><link rel="preload" href="/assets/js/app.fab0344c.js" as="script"><link rel="preload" href="/assets/js/2.1211d3e1.js" as="script"><link rel="preload" href="/assets/js/71.ed9703c6.js" as="script"><link rel="prefetch" href="/assets/js/10.a044793b.js"><link rel="prefetch" href="/assets/js/100.4399fb78.js"><link rel="prefetch" href="/assets/js/101.d91832d8.js"><link rel="prefetch" href="/assets/js/102.1705e457.js"><link rel="prefetch" href="/assets/js/103.529611c7.js"><link rel="prefetch" href="/assets/js/104.d201303c.js"><link rel="prefetch" href="/assets/js/105.aff2b5c1.js"><link rel="prefetch" href="/assets/js/106.e00a547b.js"><link rel="prefetch" href="/assets/js/107.d3f04e41.js"><link rel="prefetch" href="/assets/js/108.e74cb25c.js"><link rel="prefetch" href="/assets/js/11.5e7d0c95.js"><link rel="prefetch" href="/assets/js/12.e841c0c3.js"><link rel="prefetch" href="/assets/js/13.41a2fb93.js"><link rel="prefetch" href="/assets/js/14.e2a3317c.js"><link rel="prefetch" href="/assets/js/15.a81a6ef1.js"><link rel="prefetch" href="/assets/js/16.7b69e07f.js"><link rel="prefetch" href="/assets/js/17.777b188a.js"><link rel="prefetch" href="/assets/js/18.c81cf408.js"><link rel="prefetch" href="/assets/js/19.a59301e0.js"><link rel="prefetch" href="/assets/js/20.18827160.js"><link rel="prefetch" href="/assets/js/21.8d5d511f.js"><link rel="prefetch" href="/assets/js/22.a8ac93a6.js"><link rel="prefetch" href="/assets/js/23.1bbe4807.js"><link rel="prefetch" href="/assets/js/24.00525e76.js"><link rel="prefetch" href="/assets/js/25.3c90e0a0.js"><link rel="prefetch" href="/assets/js/26.c93f745b.js"><link rel="prefetch" href="/assets/js/27.01181006.js"><link rel="prefetch" href="/assets/js/28.93af4585.js"><link rel="prefetch" href="/assets/js/29.a0806690.js"><link rel="prefetch" href="/assets/js/3.66fedeab.js"><link rel="prefetch" href="/assets/js/30.3beac9a7.js"><link rel="prefetch" href="/assets/js/31.3ee788ac.js"><link rel="prefetch" href="/assets/js/32.6522140e.js"><link rel="prefetch" href="/assets/js/33.24b1949c.js"><link rel="prefetch" href="/assets/js/34.90e39367.js"><link rel="prefetch" href="/assets/js/35.a67486b8.js"><link rel="prefetch" href="/assets/js/36.d9ffefc3.js"><link rel="prefetch" href="/assets/js/37.e3a99db4.js"><link rel="prefetch" href="/assets/js/38.8e250355.js"><link rel="prefetch" href="/assets/js/39.fc7bdfc1.js"><link rel="prefetch" href="/assets/js/4.9805163b.js"><link rel="prefetch" href="/assets/js/40.454bd56a.js"><link rel="prefetch" href="/assets/js/41.a235b641.js"><link rel="prefetch" href="/assets/js/42.af91ee0f.js"><link rel="prefetch" href="/assets/js/43.ee9374e7.js"><link rel="prefetch" href="/assets/js/44.36c8feb3.js"><link rel="prefetch" href="/assets/js/45.d8301c73.js"><link rel="prefetch" href="/assets/js/46.9a5a32af.js"><link rel="prefetch" href="/assets/js/47.d58b6a64.js"><link rel="prefetch" href="/assets/js/48.f02903e0.js"><link rel="prefetch" href="/assets/js/49.19767842.js"><link rel="prefetch" href="/assets/js/5.c3d6e4f2.js"><link rel="prefetch" href="/assets/js/50.48750e81.js"><link rel="prefetch" href="/assets/js/51.c4254bbf.js"><link rel="prefetch" href="/assets/js/52.b343e884.js"><link rel="prefetch" href="/assets/js/53.98458ade.js"><link rel="prefetch" href="/assets/js/54.fde5639b.js"><link rel="prefetch" href="/assets/js/55.1d6eee4b.js"><link rel="prefetch" href="/assets/js/56.b00d9d45.js"><link rel="prefetch" href="/assets/js/57.eaec60f9.js"><link rel="prefetch" href="/assets/js/58.4b703868.js"><link rel="prefetch" href="/assets/js/59.26a30b6e.js"><link rel="prefetch" href="/assets/js/6.c77dab88.js"><link rel="prefetch" href="/assets/js/60.eb33df05.js"><link rel="prefetch" href="/assets/js/61.d173fa46.js"><link rel="prefetch" href="/assets/js/62.429026f8.js"><link rel="prefetch" href="/assets/js/63.b58a3d49.js"><link rel="prefetch" href="/assets/js/64.851d5d76.js"><link rel="prefetch" href="/assets/js/65.674d6d9d.js"><link rel="prefetch" href="/assets/js/66.ececc579.js"><link rel="prefetch" href="/assets/js/67.b733240a.js"><link rel="prefetch" href="/assets/js/68.6e4191d3.js"><link rel="prefetch" href="/assets/js/69.699a59ea.js"><link rel="prefetch" href="/assets/js/7.76f628a5.js"><link rel="prefetch" href="/assets/js/70.4f4dcf9b.js"><link rel="prefetch" href="/assets/js/72.b6d86aab.js"><link rel="prefetch" href="/assets/js/73.d835d9fc.js"><link rel="prefetch" href="/assets/js/74.ee7c0011.js"><link rel="prefetch" href="/assets/js/75.4db81ffe.js"><link rel="prefetch" href="/assets/js/76.0bfb8bde.js"><link rel="prefetch" href="/assets/js/77.4fb5960f.js"><link rel="prefetch" href="/assets/js/78.20e475a5.js"><link rel="prefetch" href="/assets/js/79.1fda7459.js"><link rel="prefetch" href="/assets/js/8.d2e1201f.js"><link rel="prefetch" href="/assets/js/80.b3da8d44.js"><link rel="prefetch" href="/assets/js/81.d57d0933.js"><link rel="prefetch" href="/assets/js/82.66610608.js"><link rel="prefetch" href="/assets/js/83.96744a0a.js"><link rel="prefetch" href="/assets/js/84.b9a8b20b.js"><link rel="prefetch" href="/assets/js/85.e6836d72.js"><link rel="prefetch" href="/assets/js/86.6ee49a02.js"><link rel="prefetch" href="/assets/js/87.b4c2ee51.js"><link rel="prefetch" href="/assets/js/88.a3470f95.js"><link rel="prefetch" href="/assets/js/89.dbea7400.js"><link rel="prefetch" href="/assets/js/9.2821f128.js"><link rel="prefetch" href="/assets/js/90.68c89724.js"><link rel="prefetch" href="/assets/js/91.e346339f.js"><link rel="prefetch" href="/assets/js/92.9efd417c.js"><link rel="prefetch" href="/assets/js/93.b7f17061.js"><link rel="prefetch" href="/assets/js/94.91fb98c0.js"><link rel="prefetch" href="/assets/js/95.588c9135.js"><link rel="prefetch" href="/assets/js/96.dab9ee8f.js"><link rel="prefetch" href="/assets/js/97.bbe5026d.js"><link rel="prefetch" href="/assets/js/98.967bdfe7.js"><link rel="prefetch" href="/assets/js/99.f8329907.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b0792086.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="学习笔记" class="logo"> <span class="site-name can-hide">学习笔记</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://img.jssjqd.cn/202303140455599.jpg"> <div class="blogger-info"><h3>江</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>RabbitMQ</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/9a014b/" class="sidebar-link">RabbitMQ上手以及集群机构</a></li><li><a href="/pages/696548/" class="sidebar-link">RabbitMQ docoker集群</a></li><li><a href="/pages/259322/" class="sidebar-link">RabbitMQ工作模式剖析以及常用编程模型</a></li><li><a href="/pages/ae15fa/" class="sidebar-link">RabbitMQ高级使用场景</a></li><li><a href="/pages/def779/" class="sidebar-link">RabbitMQ使用中的常见问题</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Kafka</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>RocketMQ</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97" title="分类" data-v-06225672>消息队列</a></li><li data-v-06225672><a href="/categories/?category=Kafka" title="分类" data-v-06225672>Kafka</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>江</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-11-09</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">01-VIP-Kafka快速实战与基本原理详解(2)<!----></h1>  <div class="theme-vdoing-content content__default"><p><img src="https://img.jssjqd.cn/202211091816164.jpeg" alt=""></p> <h5 id="kafka是最初由linkedin公司开发-是一个分布式、支持分区的-partition-、多副本的-replica-基于zookeeper协-调的分布式消息系统-它的最大的特性就是可以实时的处理大量数据以满足各种需求场景-比如基于hadoop的批处理系-统、低延迟的实时系统、storm-spark流式处理引擎-web-nginx日志、访问日志-消息服务等等-用scala语言编写-linkedin于2010年贡献给了apache基金会并成为顶级开源-项目。"><a href="#kafka是最初由linkedin公司开发-是一个分布式、支持分区的-partition-、多副本的-replica-基于zookeeper协-调的分布式消息系统-它的最大的特性就是可以实时的处理大量数据以满足各种需求场景-比如基于hadoop的批处理系-统、低延迟的实时系统、storm-spark流式处理引擎-web-nginx日志、访问日志-消息服务等等-用scala语言编写-linkedin于2010年贡献给了apache基金会并成为顶级开源-项目。" class="header-anchor">#</a> Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协 调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系 统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写， Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。</h5> <h4 id="kafka的使用场景"><a href="#kafka的使用场景" class="header-anchor">#</a> Kafka的使用场景</h4> <ul><li><p>日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</p></li> <li><p>消息系统：解耦和生产者和消费者、缓存消息等。</p></li> <li><p>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这 些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</p></li> <li><p>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反 馈，比如报警和报告。</p></li></ul> <p><img src="https://img.jssjqd.cn/202211091816700.png" alt="image-20221109181607285"></p> <p><strong>Kafka基本概念</strong></p> <p>kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确并<strong>没有完全遵循JMS规范。</strong></p> <p>首先，让我们来看一下基础的消息(Message)相关术语：</p> <table><thead><tr><th><strong>名称</strong></th> <th><strong>解释</strong></th></tr></thead> <tbody><tr><td>Broker</td> <td>消息中间件处理节点，一个Kafka节点就是一个broker，一 个或者多个Broker可以组成一个Kafka集群</td></tr> <tr><td>Topic</td> <td>Kafka根据topic对消息进行归类，发布到Kafka集群的每条 消息都需要指定一个topic</td></tr> <tr><td>Producer</td> <td>消息生产者，向Broker发送消息的客户端</td></tr> <tr><td>Consumer</td> <td>消息消费者，从Broker读取消息的客户端</td></tr> <tr><td>ConsumerGroup</td> <td>每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个 Consumer Group中只能有一个Consumer能够消费该消息</td></tr> <tr><td>Partition</td> <td>物理上的概念，一个topic可以分为多个partition，每个 partition内部消息是有序的</td></tr></tbody></table> <h5 id="因此-从一个较高的层面上来看-producer通过网络发送消息到kafka集群-然后consumer来进行消费-如下图"><a href="#因此-从一个较高的层面上来看-producer通过网络发送消息到kafka集群-然后consumer来进行消费-如下图" class="header-anchor">#</a> 因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费，如下图：</h5> <p><img src="media/e30239e659bd4a21589dc4051b510d52.png" alt=""></p> <p>服务端(brokers)和客户端(producer、consumer)之间通信通过<strong>TCP协议</strong>来完成。</p> <p><strong>kafka基本使用</strong></p> <h4 id="安装前的环境准备"><a href="#安装前的环境准备" class="header-anchor">#</a> 安装前的环境准备</h4> <p>由于Kafka是用Scala语言开发的，运行在JVM上，因此在安装Kafka之前需要先安装JDK。</p> <p>kafka依赖zookeeper，所以需要先安装zookeeper</p> <p><strong>第一步：下载安装包</strong></p> <p>下载2.4.1 release版本，并解压：</p> <h4 id="第二步-修改配置"><a href="#第二步-修改配置" class="header-anchor">#</a> 第二步：修改配置</h4> <p>修改配置文件config/server.properties:</p> <p><strong>第三步：启动服务</strong></p> <p>现在来启动kafka服务：</p> <p>启动脚本语法：kafka­server­start.sh [­daemon] server.properties</p> <p>可以看到，server.properties的配置路径是一个强制的参数，­daemon表示以后台进程运行，否则ssh客户端退出后， 就会停止服务。(注意，在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用vim /etc/hosts)</p> <table><thead><tr><th># 启动kafka，运行日志在logs目录的server.log文件里 bin/kafka‐server‐start.sh ‐daemon config/server.properties #后台启动，不会打印日志到控制台 或者用 bin/kafka‐server‐start.sh config/server.properties &amp; 5 # 我们进入zookeeper目录通过zookeeper客户端查看下zookeeper的目录树 bin/zkCli.sh ls / #查看zk的根目录kafka相关节点 ls /brokers/ids #查看kafka节点 10 11 # 停 止 kafka</th> <th></th> <th></th> <th></th></tr></thead> <tbody><tr><td>12 bin/</td> <td>kafka</td> <td>‐server‐</td> <td>stop.sh</td></tr></tbody></table> <p><strong>server.properties核心配置详解：</strong></p> <table><thead><tr><th><strong>Property</strong></th> <th><strong>Default</strong></th> <th><strong>Description</strong></th></tr></thead> <tbody><tr><td>broker.id</td> <td>0</td> <td>每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“ 你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。</td></tr> <tr><td>log.dirs</td> <td>/tmp/kafka-logs</td> <td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用 隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。</td></tr> <tr><td>listeners</td> <td>PLAINTEXT://192.168.65.60:909 2</td> <td>server接受客户端连接的端口，ip配置kafka本机ip即可</td></tr> <tr><td>zookeeper.connect</td> <td>localhost:2181</td> <td>zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3</td></tr></tbody></table> <table><thead><tr><th>log.retention.hours</th> <th>168</th> <th>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。</th></tr></thead> <tbody><tr><td>num.partitions</td> <td>1</td> <td>创建topic的默认分区数</td></tr> <tr><td>default.replication.factor</td> <td>1</td> <td>自动创建topic的默认副本数量，建议设置为大于等于2</td></tr> <tr><td>min.insync.replicas</td> <td>1</td> <td>当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须 个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产</td></tr> <tr><td>delete.topic.enable</td> <td>false</td> <td>是否允许删除主题</td></tr> <tr><td></td> <td></td> <td></td></tr></tbody></table> <p><strong>第四步：创建主题</strong></p> <p>现在我们来创建一个名字为“test”的Topic，这个topic只有一个partition，并且备份因子也设置为1：</p> <p>现在我们可以通过以下命令来查看kafka中目前存在的topic</p> <p>除了我们通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创 建。</p> <p><strong>删除主题</strong></p> <p><strong>第五步：发送消息</strong></p> <p>kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这 些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。</p> <p>首先我们要运行发布消息的脚本，然后在命令中输入要发送的消息的内容：</p> <p><strong>第六步：消费消息</strong></p> <p>对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，<strong>默认是消费最新的消息</strong>：</p> <p>如果想要消费之前的消息可以通过--from-beginning参数指定，如下命令：</p> <p>如果你是通过不同的终端窗口来运行以上的命令，你将会看到在producer终端输入的内容，很快就会在consumer的终 端窗口上显示出来。</p> <p>以上所有的命令都有一些附加的选项；当我们不携带任何参数运行命令的时候，将会显示出这个命令的详细用法。 <strong>消费多主题</strong></p> <p><strong>单播消费</strong></p> <p>一条消息只能被某一个消费者消费的模式，类似queue模式，只需让所有消费者在同一个消费组里即可 分别在两个客户端执行如下消费命令，然后往主题里发送消息，结果只有一个客户端能收到消息</p> <p><strong>多播消费</strong></p> <p>一条消息能被多个消费者消费的模式，类似publish-subscribe模式费，针对Kafka同一条消息只能被同一个消费组下的某一个消 费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。我们再增加一个消费者，该消费者属于testGroup-2消费</p> <p>组，结果两个客户端都能收到消息</p> <p><strong>查看消费组名</strong></p> <p><strong>查看消费组的消费偏移量</strong></p> <p><img src="media/5b8067a1d2aae3923c9fd25cf0c20890.jpeg" alt=""></p> <p>**current-offset：**当前消费组的已消费偏移量</p> <p>**log-end-offset：**主题对应分区消息的结束偏移量(HW) **lag：**当前消费组未消费的消息数</p> <h2 id="主题topic和消息日志log"><a href="#主题topic和消息日志log" class="header-anchor">#</a> 主题Topic和消息日志Log</h2> <p>可以理解<strong>Topic是一个类别的名称</strong>，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(**Partition)**日志文件:</p> <p><img src="media/de06337667111b6ac2518d505a9bb990.png" alt=""></p> <p>Partition是一个<strong>有序的message序列</strong>，这些message按顺序添加到一个叫做<strong>commit log的文件</strong>中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message。</p> <p><strong>每个partition，都对应一个commit log文件</strong>。一个partition中的message的offset都是唯一的，但是不同的partition 中的message的offset可能是相同的。</p> <h5 id="kafka一般不会删除消息-不管这些消息有没有被消费。只会根据配置的日志保留时间-log-retention-hours-确认消息多-久被删除-默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系-因此保存大量的数据消息日-志信息不会有什么影响。"><a href="#kafka一般不会删除消息-不管这些消息有没有被消费。只会根据配置的日志保留时间-log-retention-hours-确认消息多-久被删除-默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系-因此保存大量的数据消息日-志信息不会有什么影响。" class="header-anchor">#</a> kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多 久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日 志信息不会有什么影响。</h5> <p><strong>每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的</strong>。在kafka中，<strong>消费offset由consumer自</strong></p> <p><strong>己来维护</strong>；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息， 或者跳过某些消息。</p> <p>这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer 来说，都是没有影响的，因为每个consumer维护各自的消费offset。</p> <p><strong>创建多个分区的主题：</strong></p> <p><strong>查看下topic的情况</strong></p> <p><img src="media/2ce4a7448b9f4dac5c60916aefd5fb7a.png" alt=""></p> <p>以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。</p> <p>leader节点负责给定partition的所有读写请求。</p> <p>replicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。 isr 是replicas的一个子集，它只列出当前还存活着的，并且<strong>已同步备份</strong>了该partition的节点。</p> <p>我们可以运行相同的命令查看之前创建的名称为”test“的topic</p> <p><img src="media/545d8a7f2601c013fe285b18ad826a81.png" alt=""></p> <p>之前设置了topic的partition数量为1，备份因子为1，因此显示就如上所示了。</p> <p>可以进入kafka的数据文件存储目录查看test和test1主题的消息日志文件：</p> <p><img src="media/e45734f37777cd4f0902cabc9859375b.png" alt=""></p> <p>消息日志文件主要存放在分区文件夹里的以log结尾的日志文件里，如下是test1主题对应的分区0的消息日志：</p> <p><img src="media/bc71af91f663abadda32a64e792562c9.png" alt=""></p> <p>当然我们也可以通过如下命令<strong>增加topic的分区数量(目前kafka不支持减少分区)</strong>：</p> <p><strong>可以这么来理解Topic，Partition和Broker</strong></p> <h5 id="一个topic-代表逻辑上的一个业务数据集-比如按数据库里不同表的数据操作消息区分放入不同topic-订单相关操作消-息放入订单topic-用户相关操作消息放入用户topic-对于大型网站来说-后端数据都是海量的-订单消息很可能是非常-巨量的-比如有几百个g甚至达到tb级别-如果把这么多数据都放在一台机器上可定会有容量限制问题-那么就可以在-topic内部划分多个partition来分片存储数据-不同的partition可以位于不同的机器上-每台机器上都运行一个kafka的-进程broker。"><a href="#一个topic-代表逻辑上的一个业务数据集-比如按数据库里不同表的数据操作消息区分放入不同topic-订单相关操作消-息放入订单topic-用户相关操作消息放入用户topic-对于大型网站来说-后端数据都是海量的-订单消息很可能是非常-巨量的-比如有几百个g甚至达到tb级别-如果把这么多数据都放在一台机器上可定会有容量限制问题-那么就可以在-topic内部划分多个partition来分片存储数据-不同的partition可以位于不同的机器上-每台机器上都运行一个kafka的-进程broker。" class="header-anchor">#</a> 一个topic，代表逻辑上的一个业务数据集，比如按数据库里不同表的数据操作消息区分放入不同topic，订单相关操作消 息放入订单topic，用户相关操作消息放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常 巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在 topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的 进程Broker。</h5> <p><strong>为什么要对Topic下数据进行分区存储？</strong></p> <p>1、commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据。</p> <p>2、为了<strong>提高并行度</strong>。</p> <h1 id="kafka集群实战"><a href="#kafka集群实战" class="header-anchor">#</a> kafka集群实战</h1> <h5 id="对于kafka来说-一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量-只需要多启动-几个broker实例即可。为了有更好的理解-现在我们在一台机器上同时启动三个broker实例。"><a href="#对于kafka来说-一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量-只需要多启动-几个broker实例即可。为了有更好的理解-现在我们在一台机器上同时启动三个broker实例。" class="header-anchor">#</a> 对于kafka来说，一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动 几个broker实例即可。为了有更好的理解，现在我们在一台机器上同时启动三个broker实例。</h5> <p>首先，我们需要建立好其他2个broker的配置文件：</p> <p>配置文件的需要修改的内容分别如下： config/server-1.properties:</p> <table><thead><tr><th>#broker.id属性在kafka集群中必须要是唯一 broker.id=1 #kafka部署的机器ip和提供服务的端口号</th> <th></th></tr></thead> <tbody><tr><td>4 listeners</td> <td>=PLAINTEXT://192.168.65.60:9093</td></tr></tbody></table> <p>config/server-2.properties:</p> <table><thead><tr><th>broker.id listeners</th> <th>=2 =PLAINTEXT://192.168.65.60:9094</th></tr></thead> <tbody><tr><td>3 log.dir=/usr/local/data/kafka‐logs‐2 4 zookeeper.connect=192.168.65.60:2181</td> <td></td></tr></tbody></table> <p>目前我们已经有一个zookeeper实例和一个broker实例在运行了，现在我们只需要在启动2个broker实例即可：</p> <p><strong>查看zookeeper确认集群节点是否都注册成功：</strong></p> <p><img src="media/6f739981d68ba3284d57be3aea5e5678.png" alt=""></p> <h5 id="现在我们创建一个新的topic-副本数设置为3-分区数设置为2"><a href="#现在我们创建一个新的topic-副本数设置为3-分区数设置为2" class="header-anchor">#</a> 现在我们创建一个新的topic，副本数设置为3，分区数设置为2：</h5> <p><strong>查看下topic的情况</strong></p> <p><img src="media/9536bc37db28f7f41ce875a9e5555091.png" alt=""></p> <p>以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。</p> <p>leader节点负责给定partition的所有读写请求，同一个主题不同分区leader副本一般不一样(为了容灾)</p> <p>replicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。 isr 是replicas的一个子集，它只列出当前还存活着的，并且<strong>已同步备份</strong>了该partition的节点。</p> <p>现在我们向新建的 my-replicated-topic 中发送一些message，kafka集群可以加上所有kafka节点：</p> <h5 id="现在开始消费"><a href="#现在开始消费" class="header-anchor">#</a> 现在开始消费：</h5> <p>现在我们来测试我们容错性，因为broker1目前是my-replicated-topic的分区0的leader，所以我们要将其kill</p> <table><thead><tr><th>1 ps ‐</th> <th>ef |</th> <th>grep server.properties</th></tr></thead> <tbody><tr><td>2 kill 14776</td> <td></td> <td></td></tr></tbody></table> <h5 id="现在再执行命令"><a href="#现在再执行命令" class="header-anchor">#</a> 现在再执行命令：</h5> <p><img src="media/1ec0643b851e31e50ca82c11b80edfc8.png" alt=""></p> <p>我们可以看到，分区0的leader节点已经变成了broker 0。要注意的是，在Isr中，已经没有了1号节点。leader的选举也是从ISR(in-sync replica)中进行的。</p> <p>此时，我们依然可以 消费新消息：</p> <p>查看主题分区对应的leader信息：</p> <p><img src="media/f84f2469e9327c359d8f6faf415359b5.png" alt=""></p> <p><strong>kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便。</strong></p> <p><strong>集群消费</strong></p> <p>log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka 集群支持配置一个partition备份的数量。</p> <p>针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。 <strong>leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多 副本数据与消费的一致性)</strong>。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。</p> <p><strong>Producers</strong></p> <h5 id="生产者将消息发送到topic中去-同时负责选择将message发送到topic的哪一个partition中。通过round­robin做简单的-负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。"><a href="#生产者将消息发送到topic中去-同时负责选择将message发送到topic的哪一个partition中。通过round­robin做简单的-负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。" class="header-anchor">#</a> 生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round­robin做简单的 负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。</h5> <p><strong>Consumers</strong></p> <p>传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）</p> <p>queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。publish-subscribe模式：消息会被广播给所有的consumer。</p> <p>Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。queue模式：所有的consumer都位于同一个consumer group 下。</p> <p>publish-subscribe模式：所有的consumer都有着自己唯一的consumer group。</p> <p><img src="media/fde5cc57ae03e07f83afeee877c6d50c.png" alt=""></p> <p>上图说明：由2个broker组成的kafka集群，某个主题总共有4个partition(P0-P3)，分别位于不同的broker上。这个集群 由2个Consumer Group消费， A有2个consumer instances ，B有4个。</p> <p>通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。</p> <p><strong>消费顺序</strong></p> <p>一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。<strong>consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。</strong></p> <h5 id="kafka只在partition的范围内保证消息消费的局部顺序性-不能在同一个topic中的多个partition中保证总的消费顺序-性。"><a href="#kafka只在partition的范围内保证消息消费的局部顺序性-不能在同一个topic中的多个partition中保证总的消费顺序-性。" class="header-anchor">#</a> Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序 性。</h5> <p>如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。</p> <p><strong>Java客户端访问Kafka</strong></p> <p>引入maven依赖</p> <p>消息发送端代码</p> <ol><li><p>props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);</p></li> <li><p>//设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</p></li> <li><p>props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);</p> <p>36 *//*</p></li> <li><p>kafka本地线程会从缓冲区取数据，批量发送到broker，</p></li> <li><p>设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</p> <p>39 *//*</p> <p>40 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);</p> <p>41 *//*</p></li> <li><p>默认值是0，意思就是消息必须立即被发送，但这样会影响性能</p></li> <li><p>一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去</p></li> <li><p>如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长</p> <p>45 *//*</p></li> <li><p>props.put(ProducerConfig.LINGER_MS_CONFIG, 10);*/</p></li> <li><p>//把发送的key从字符串序列化为字节数组</p></li> <li><p>props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</p></li> <li><p>//把发送消息value从字符串序列化为字节数组</p></li> <li><p>props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</p> <p>51</p> <p>52 Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);</p> <p>53</p></li> <li><p>int msgNum = 5;</p></li> <li><p>final CountDownLatch countDownLatch = new CountDownLatch(msgNum);</p></li> <li><p>for (int i = 1; i &lt;= msgNum; i++) {</p></li> <li><p>Order order = new Order(i, 100 + i, 1, 1000.00);</p></li> <li><p>//指定发送分区</p></li> <li><p>/*ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME</p></li> <li><p>, 0, order.getOrderId().toString(), JSON.toJSONString(order));*/</p></li> <li><p>//未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum</p></li> <li><p>ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME</p></li> <li><p>, order.getOrderId().toString(), JSON.toJSONString(order));</p> <p>64</p></li> <li><p>//等待消息发送成功的同步阻塞方法</p></li> <li><p>/*RecordMetadata metadata = producer.send(producerRecord).get();</p></li> <li><p>System.out.println(&quot;同步方式发送消息结果：&quot; + &quot;topic‐&quot; + metadata.topic() + &quot;|partition‐&quot;</p> <p>68 + metadata.partition() + &quot;|offset‐&quot; + metadata.offset());*/</p> <p>69</p></li> <li><p>//异步回调方式发送消息</p></li> <li><p>producer.send(producerRecord, new Callback() {</p></li> <li><p>public void onCompletion(RecordMetadata metadata, Exception exception) {</p></li> <li><p>if (exception != null) {</p></li> <li><p>System.err.println(&quot;发送消息失败：&quot; + exception.getStackTrace());</p> <p>75</p> <p>76 }</p></li> <li><p>if (metadata != null) {</p></li> <li><p>System.out.println(&quot;异步方式发送消息结果：&quot; + &quot;topic‐&quot; + metadata.topic() + &quot;|partition‐&quot;</p> <p>79 + metadata.partition() + &quot;|offset‐&quot; + metadata.offset());</p> <p>80 }</p> <p>81 countDownLatch.countDown();</p> <p>82 }</p> <p>83 });</p> <p>84</p> <p>85 // 送 积 分 TODO</p> <p>86</p> <p>87 }</p> <p>88</p></li> <li><p>countDownLatch.await(5, TimeUnit.SECONDS);</p></li> <li><p>producer.close();</p> <p>91 }</p> <p>92 }</p></li></ol> <p>消息接收端代码</p> <p>1 package com.tuling.kafka.kafkaDemo;</p> <p>2</p> <ol><li><p>import org.apache.kafka.clients.consumer.ConsumerConfig;</p></li> <li><p>import org.apache.kafka.clients.consumer.ConsumerRecord;</p></li> <li><p>import org.apache.kafka.clients.consumer.ConsumerRecords;</p></li> <li><p>import org.apache.kafka.clients.consumer.KafkaConsumer;</p></li> <li><p>import org.apache.kafka.common.serialization.StringDeserializer;</p> <p>8</p></li> <li><p>import java.time.Duration;</p></li> <li><p>import java.util.Arrays;</p></li> <li><p>import java.util.Properties;</p> <p>12</p></li> <li><p>public class MsgConsumer {</p></li> <li><p>private final static String TOPIC_NAME = &quot;my‐replicated‐topic&quot;;</p></li> <li><p>private final static String CONSUMER_GROUP_NAME = &quot;testGroup&quot;;</p> <p>16</p></li> <li><p>public static void main(String[] args) {</p></li> <li><p>Properties props = new Properties();</p> <p>19 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094&quot;);</p></li> <li><p>// 消费分组名</p></li> <li><p>props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);</p></li> <li><p>// 是否自动提交offset，默认就是true</p></li> <li><p>props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);</p></li> <li><p>// 自动提交offset的间隔时间</p></li> <li><p>props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);</p></li> <li><p>//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);</p> <p>27 /*</p></li> <li><p>当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费</p></li> <li><p>latest(默认) ：只消费自己启动之后发送到主题的消息</p></li> <li><p>earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)</p> <p>31 */</p> <p>32 //props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);</p> <p>33 /*</p></li> <li><p>consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将</p></li> <li><p>rebalance方案下发给consumer，这个时间可以稍微短一点</p> <p>36 */</p> <p>37 props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);</p> <p>38 /*</p></li> <li><p>服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，</p></li> <li><p>对应的Partition也会被重新分配给其他consumer，默认是10秒</p> <p>41 */</p></li> <li><p>props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);</p></li> <li><p>//一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</p></li> <li><p>props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);</p> <p>45 /*</p></li> <li><p>如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，</p></li> <li><p>会将其踢出消费组，将分区分配给别的consumer消费</p> <p>48 */</p></li> <li><p>props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);</p></li> <li><p>props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</p></li> <li><p>props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</p></li> <li><p>KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);</p> <p>53</p></li> <li><p>consumer.subscribe(Arrays.asList(TOPIC_NAME));</p></li> <li><p>// 消费指定分区</p></li> <li><p>//consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</p> <p>57</p></li> <li><p>//消息回溯消费</p></li> <li><p>/*consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</p></li> <li><p>consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));*/</p> <p>61</p></li> <li><p>//指定offset消费</p></li> <li><p>/*consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));</p></li> <li><p>consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);*/</p> <p>65</p></li> <li><p>//从指定时间点开始消费</p></li> <li><p>/*List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);</p></li> <li><p>//从1小时前开始消费</p></li> <li><p>long fetchDataTime = new Date().getTime() ‐ 1000 * 60 * 60;</p></li> <li><p>Map&lt;TopicPartition, Long&gt; map = new HashMap&lt;&gt;();</p></li> <li><p>for (PartitionInfo par : topicPartitions) {</p></li> <li><p>map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);</p> <p>73 }</p></li> <li><p>Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);</p></li> <li><p>for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) {</p></li> <li><p>TopicPartition key = entry.getKey();</p></li> <li><p>OffsetAndTimestamp value = entry.getValue();</p></li> <li><p>if (key == null || value == null) continue;</p></li> <li><p>Long offset = value.offset();</p></li> <li><p>System.out.println(&quot;partition‐&quot; + key.partition() + &quot;|offset‐&quot; + offset);</p></li> <li><p>System.out.println();</p></li> <li><p>//根据消费里的timestamp确定offset</p></li> <li><p>if (value != null) {</p></li> <li><p>consumer.assign(Arrays.asList(key));</p></li> <li><p>consumer.seek(key, offset);</p> <p>86 }</p> <p>87 }*/</p> <p>88</p> <p>89 while (true) {</p> <p>90 /*</p> <p>91 * poll() API 是拉取消息的长轮询</p> <p>92 */</p></li> <li><p>ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000));</p></li> <li><p>for (ConsumerRecord&lt;String, String&gt; record : records) {</p></li> <li><p>System.out.printf(&quot;收到消息：partition = %d,offset = %d, key = %s, value = %s%n&quot;, record.partition(),</p></li> <li><p>record.offset(), record.key(), record.value());</p> <p>97 }</p> <p>98</p></li> <li><p>/*if (records.count() &gt; 0) {</p></li> <li><p>// 手动同步提交offset，当前线程会阻塞直到offset提交成功</p></li> <li><p>// 一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</p></li> <li><p>consumer.commitSync();</p></li> <li></li> <li><p>// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</p></li> <li><p>consumer.commitAsync(new OffsetCommitCallback() {</p></li> <li><p>@Override</p></li> <li><p>public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) {</p></li> <li><p>if (exception != null) {</p></li> <li><p>System.err.println(&quot;Commit failed for &quot; + offsets);</p></li> <li><p>System.err.println(&quot;Commit failed exception: &quot; + exception.getStackTrace());</p> <p>111 }</p> <p>112 }</p> <p>113 });</p> <p>114</p> <p>115 }*/</p> <p>116 }</p> <p>117 }</p> <p>118 }</p></li></ol> <h3 id="spring-boot整合kafka"><a href="#spring-boot整合kafka" class="header-anchor">#</a> Spring Boot整合Kafka</h3> <p>引入spring boot kafka依赖，详见项目实例：spring-boot-kafka</p> <p>application.yml配置如下：</p> <p>发送者代码：</p> <p>消费者代码：</p></div></div>  <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/03/22, 15:37:51</span></div></div> <div class="page-nav-wapper"><!----> <!----></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/85c8b9/"><div>
            Tomcat整体架构及其设计精髓
            <!----></div></a> <span class="date">03-22</span></dt></dl><dl><dd>02</dd> <dt><a href="/15.Netty/00.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E5%92%8CTCP%20IP%E5%8D%8F%E8%AE%AE.html"><div>
            网络协议
            <!----></div></a> <span class="date"></span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/bc8703/"><div>
            JVM调优实战及常量池详解
            <!----></div></a> <span class="date">03-14</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:894072666@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/xugaoyi" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2023
    <span>江</span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.fab0344c.js" defer></script><script src="/assets/js/2.1211d3e1.js" defer></script><script src="/assets/js/71.ed9703c6.js" defer></script>
  </body>
</html>
